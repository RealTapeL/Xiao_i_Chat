# æœ¬é¡¹ç›®æ•°æ®é›†æ„å»º
> å…·ä½“å†…å®¹ä¸ä¸€ä¸€ä»‹ç»ï¼Œç‚¹è¿›jsonæ–‡ä»¶çœ‹å³å¯ï¼Œå¤šçœ‹å¤šåšæ˜¯æœ€é‡è¦çš„ã€‚æ•°æ®é›†ä¼šä¸€ç›´æ›´æ–°ã€‚
## æŒ‡ä»¤é›†æ„å»º â€”â€” Alpaca æ ¼å¼
æœ¬æ–‡æ‰€æœ‰ç¨‹åºã€è„šæœ¬ä¸æ¨¡å‹ä»…æ”¯æŒæ”¯æŒAlpacaæ ¼å¼çš„æ•°æ®é›†,æ­£ç¡®æ ¼å¼å†…å®¹å¦‚ä¸‹
```
[
  {
    "instruction": "äººç±»æŒ‡ä»¤ï¼ˆå¿…å¡«ï¼‰",
    "input": "äººç±»è¾“å…¥ï¼ˆé€‰å¡«ï¼‰",
    "output": "æ¨¡å‹å›ç­”ï¼ˆå¿…å¡«ï¼‰",
    "system": "ç³»ç»Ÿæç¤ºè¯ï¼ˆé€‰å¡«ï¼‰",
    "history": [
      ["ç¬¬ä¸€è½®æŒ‡ä»¤ï¼ˆé€‰å¡«ï¼‰", "ç¬¬ä¸€è½®å›ç­”ï¼ˆé€‰å¡«ï¼‰"],
      ["ç¬¬äºŒè½®æŒ‡ä»¤ï¼ˆé€‰å¡«ï¼‰", "ç¬¬äºŒè½®å›ç­”ï¼ˆé€‰å¡«ï¼‰"]
    ]
  }
]
```
åœ¨æŒ‡ä»¤ç›‘ç£å¾®è°ƒæ—¶ï¼Œ`instruction` åˆ—å¯¹åº”çš„å†…å®¹ä¼šä¸ `input` åˆ—å¯¹åº”çš„å†…å®¹æ‹¼æ¥åä½œä¸ºäººç±»æŒ‡ä»¤ï¼Œå³äººç±»æŒ‡ä»¤ä¸º `instruction\ninput`ã€‚è€Œ `output` åˆ—å¯¹åº”çš„å†…å®¹ä¸ºæ¨¡å‹å›ç­”ã€‚

å¦‚æœæŒ‡å®šï¼Œ`system` åˆ—å¯¹åº”çš„å†…å®¹å°†è¢«ä½œä¸ºç³»ç»Ÿæç¤ºè¯ã€‚

`history` åˆ—æ˜¯ç”±å¤šä¸ªå­—ç¬¦ä¸²äºŒå…ƒç»„æ„æˆçš„åˆ—è¡¨ï¼Œåˆ†åˆ«ä»£è¡¨å†å²æ¶ˆæ¯ä¸­æ¯è½®å¯¹è¯çš„æŒ‡ä»¤å’Œå›ç­”ã€‚æ³¨æ„åœ¨æŒ‡ä»¤ç›‘ç£å¾®è°ƒæ—¶ï¼Œå†å²æ¶ˆæ¯ä¸­çš„å›ç­”å†…å®¹ä¹Ÿä¼šè¢«ç”¨äºæ¨¡å‹å­¦ä¹ ã€‚

## å•è½®å¯¹è¯æ•°æ®çš„æ ¼å¼è½¬æ¢
ä½¿ç”¨ä»¥ä¸‹ç¨‹åºå°†å•è½®å¯¹è¯æ•°æ®é›†è½¬æ¢æˆ alpaca æ ¼å¼
```
import json
import re

# é€‰æ‹©è¦æ ¼å¼è½¬æ¢çš„æ•°æ®é›†
file_name = "single_turn_dataset_1.json"
#file_name = "single_turn_dataset_2.json"

system_prompt = "å¦‚æœè¦æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼Œè¯·æ”¾åœ¨è¿™é‡Œ"

with open(f'../{file_name}', 'rt', encoding='utf-8') as file:
    data = json.load(file)

converted_data = [{"instruction": item["prompt"], 
                   "input": "", 
                   "output": item["completion"],
                   "system": system_prompt
                  } for item in data]

for i in range(len(converted_data)):

    # æ•°æ®æ¸…æ´—-å»æ‰ç‰¹æ®Šç¬¦å·
    if "ğŸ³" in converted_data[i]["output"]:
        converted_data[i]["output"] = converted_data[i]["output"].replace("ğŸ³", "")
        
    # æ•°æ®æ¸…æ´—-å»æ‰â€œä½ å¥½ï¼Œæˆ‘æ˜¯çº¢çƒ§è‚‰â€ï¼Œä¼šå½±å“å¤§æ¨¡å‹çš„è‡ªæˆ‘è®¤çŸ¥
    if 'å¥½ï¼Œæˆ‘æ˜¯' in converted_data[i]["output"]:
        converted_data[i]["output"] = converted_data[i]["output"].strip()
        intro_pattern = r"^[^\n]+\n"
        converted_data[i]["output"] = re.sub(intro_pattern, "", converted_data[i]["output"]).strip() 

with open(f'./processed/{file_name}', 'w', encoding='utf-8') as f:
    json.dump(converted_data, f, ensure_ascii=False, indent=4)
print(f'./processed/{file_name} Done')
```
## å¤šè½®å¯¹è¯æ•°æ®çš„æ ¼å¼è½¬æ¢
ä½¿ç”¨ä»¥ä¸‹ç¨‹åºå°†å¤šè½®å¯¹è¯è½¬æ¢æˆ alpaca æ ¼å¼
```
from tqdm import tqdm
import json

# é€‰æ‹©è¦æ ¼å¼è½¬æ¢çš„æ•°æ®é›†
file_name = "data.json"
#file_name = "data_pro.json"
#file_name = "multi_turn_dataset_1.json"
#file_name = "multi_turn_dataset_2.json"
#file_name = "aiwei.json"

system_prompt = "å¦‚æœè¦æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼Œè¯·æ”¾åœ¨è¿™é‡Œ"

with open(f'../{file_name}', 'rt', encoding='utf-8') as file:
    data = json.load(file)

# éå†åŸå§‹æ•°æ®ï¼Œè¿›è¡Œæ ¼å¼è½¬æ¢

# è½¬æ¢åçš„æ•°æ®æ ¼å¼
converted_data = []
for item in tqdm(data):
    conversation = item['conversation']
    history = [(c['input'], c['output']) for c in conversation[:-1]]
    last_item = conversation[-1]
    converted_data.append({
        "instruction": last_item['input'],
        "input": "",
        "output": last_item['output'],
        "system": system_prompt,
        "history": history
    })
    # å°†è½¬æ¢åçš„æ•°æ®è½¬æ¢ä¸ºJSONæ ¼å¼
    converted_json = json.dumps(converted_data, ensure_ascii=False, indent=4)

with open(f'./processed/{file_name}', 'w', encoding='utf-8') as f:
    json.dump(converted_data, f, ensure_ascii=False, indent=4)
```
## è§’è‰²æ‰®æ¼”æ•°æ®çš„æ ¼å¼è½¬æ¢
ä»£ç åŒä¸Šï¼Œæ ¹æ®åŸæ•°æ®é›†æ˜¯å•è½®å¯¹è¯è¿˜æ˜¯å¤šè½®å¯¹è¯æ¥é€‰æ‹©ã€‚æ³¨æ„è®¾ç½®å„ä¸ªè§’è‰²çš„â€œsystem_promptâ€ã€‚
